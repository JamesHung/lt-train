package lrucache

import "fmt"

const debugLRU = false

// LRUCache implements a least-recently-used cache with O(1) get/put using a map + doubly linked list.
type LRUCache struct {
	capacity int
	items    map[int]*node
	head     *node
	tail     *node
}

type node struct {
	key   int
	value int
	prev  *node
	next  *node
}

// Constructor initializes the cache with the given capacity.
func Constructor(capacity int) LRUCache {
	head := &node{}
	tail := &node{}
	head.next = tail
	tail.prev = head

	return LRUCache{
		capacity: capacity,
		items:    make(map[int]*node, capacity),
		head:     head,
		tail:     tail,
	}
}

// Get returns the value for key if present, otherwise -1.
func (c *LRUCache) Get(key int) int {
	if n, ok := c.items[key]; ok {
		c.moveToFront(n)
		if debugLRU {
			fmt.Printf("get key=%d value=%d\n", key, n.value)
		}
		return n.value
	}
	if debugLRU {
		fmt.Printf("get key=%d miss\n", key)
	}
	return -1
}

// Put inserts or updates the key with value, evicting if necessary.
func (c *LRUCache) Put(key int, value int) {
	if n, ok := c.items[key]; ok {
		n.value = value
		c.moveToFront(n)
		if debugLRU {
			fmt.Printf("put update key=%d value=%d\n", key, value)
		}
		return
	}

	if len(c.items) == c.capacity {
		c.evictLRU()
	}

	n := &node{key: key, value: value}
	c.items[key] = n
	c.insertAfterHead(n)
	if debugLRU {
		fmt.Printf("put insert key=%d value=%d\n", key, value)
	}
}

func (c *LRUCache) moveToFront(n *node) {
	c.remove(n)
	c.insertAfterHead(n)
}

func (c *LRUCache) insertAfterHead(n *node) {
	n.prev = c.head
	n.next = c.head.next
	c.head.next.prev = n
	c.head.next = n
}

func (c *LRUCache) remove(n *node) {
	n.prev.next = n.next
	n.next.prev = n.prev
}

func (c *LRUCache) evictLRU() {
	lru := c.tail.prev
	if lru == c.head {
		return
	}
	if debugLRU {
		fmt.Printf("evict key=%d value=%d\n", lru.key, lru.value)
	}
	c.remove(lru)
	delete(c.items, lru.key)
}
